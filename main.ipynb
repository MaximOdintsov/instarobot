{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–æ–±–æ—Ç–∞ selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from robot.helpers.selenium_management import open_link, get_wait_element, get_wait_elements, get_link_elements, get_links, start_driver, close_driver\n",
    "\n",
    "from robot.conf import config\n",
    "from robot.helpers.utils import (\n",
    "    extract_emails,\n",
    "    validate_instagram_url,\n",
    "    POST_VALUE,\n",
    "    ACCOUNT_VALUE\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets.readonly\"]\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "SAMPLE_SPREADSHEET_ID = \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\"\n",
    "SAMPLE_RANGE_NAME = \"Class Data!A2:E\"\n",
    "\n",
    "\n",
    "def main():\n",
    "  \"\"\"Shows basic usage of the Sheets API.\n",
    "  Prints values from a sample spreadsheet.\n",
    "  \"\"\"\n",
    "  creds = None\n",
    "  # The file token.json stores the user's access and refresh tokens, and is\n",
    "  # created automatically when the authorization flow completes for the first\n",
    "  # time.\n",
    "  if os.path.exists(\"token.json\"):\n",
    "    creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "  # If there are no (valid) credentials available, let the user log in.\n",
    "  if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "      creds.refresh(Request())\n",
    "    else:\n",
    "      flow = InstalledAppFlow.from_client_secrets_file(\n",
    "          \"credentials.json\", SCOPES\n",
    "      )\n",
    "      creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open(\"token.json\", \"w\") as token:\n",
    "      token.write(creds.to_json())\n",
    "\n",
    "  try:\n",
    "    service = build(\"sheets\", \"v4\", credentials=creds)\n",
    "\n",
    "    # Call the Sheets API\n",
    "    sheet = service.spreadsheets()\n",
    "    result = (\n",
    "        sheet.values()\n",
    "        .get(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=SAMPLE_RANGE_NAME)\n",
    "        .execute()\n",
    "    )\n",
    "    values = result.get(\"values\", [])\n",
    "\n",
    "    if not values:\n",
    "      print(\"No data found.\")\n",
    "      return\n",
    "\n",
    "    print(\"Name, Major:\")\n",
    "    for row in values:\n",
    "      # Print columns A and E, which correspond to indices 0 and 4.\n",
    "      print(f\"{row[0]}, {row[4]}\")\n",
    "  except HttpError as err:\n",
    "    print(err)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from robot.ml.custom_transformers import TextCleaner, DomainBinarizer\n",
    "from robot.models import AccountType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ARTIST       0.89      0.92      0.90        36\n",
      "   BEATMAKER       1.00      0.50      0.67         2\n",
      "   COMMUNITY       0.78      0.95      0.86        19\n",
      "       LABEL       1.00      0.60      0.75         5\n",
      "      MARKET       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.87        68\n",
      "   macro avg       0.93      0.73      0.80        68\n",
      "weighted avg       0.88      0.87      0.86        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# –®–∞–≥ 1: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "##################################\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ DataFrame\n",
    "file_path = 'data/mod–µls/train_data/merged_table.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# –ó–∞–º–µ–Ω–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "df.fillna(\n",
    "    {   \n",
    "        '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞': 'OTHER',\n",
    "        '–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã': '',\n",
    "        '–°—Å—ã–ª–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è': '', \n",
    "        '–°—Å—ã–ª–∫–∏ –∏–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤': '',\n",
    "        '–ö–æ–ª-–≤–æ –ø–æ—Å—Ç–æ–≤': 0\n",
    "    }, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# 1 —à–∞–≥: –ó–∞–º–µ–Ω–∞ –∏–º–µ–Ω–∏ —Å—Ç–æ–ª–±—Ü–∞\n",
    "# 2 —à–∞–≥: –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫ —Å —Ç–∏–ø–æ–º \"OTHER\"\n",
    "df.rename(columns={\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞\": \"–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞\"}, inplace=True)\n",
    "# df = df[df[\"–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞\"] != \"OTHER\"]\n",
    "\n",
    "# –ó–∞–º–µ–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ç–æ–ª–±—Ü–∞ –Ω–∞ 1, –µ—Å–ª–∏ –Ω–µ NaN, –∏ –Ω–∞ 0, –µ—Å–ª–∏ NaN\n",
    "# 1 —à–∞–≥ - –∑–∞–º–µ–Ω–∞ –Ω–∞ True –∏ False\n",
    "# 2 —à–∞–≥ - –∑–∞–º–µ–Ω–∞ –Ω–∞ 1 –∏ 0\n",
    "df['–ü–æ—á—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç'] = df['–ù–∞–π–¥–µ–Ω–Ω–∞—è –ø–æ—á—Ç–∞'].notna().astype(int)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∞—Ö —á–µ—Ä–µ–∑ '\\n'\n",
    "df['–°—Å—ã–ª–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è'] = df['–°—Å—ã–ª–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è'].str.split('\\n')\n",
    "df['–°—Å—ã–ª–∫–∏ –∏–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤'] = df['–°—Å—ã–ª–∫–∏ –∏–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤'].str.split('\\n')\n",
    "\n",
    "\n",
    "##################################\n",
    "# –®–∞–≥ 2: –î–µ–ª–∏–º –Ω–∞ X –∏ y + —Ä–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "##################################\n",
    "X = df[[\n",
    "    \"–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã\",  # text\n",
    "    \"–°—Å—ã–ª–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è\",  # text\n",
    "    \"–°—Å—ã–ª–∫–∏ –∏–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤\",  # text\n",
    "    \"–ü–æ—á—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\",  # 1/0\n",
    "    \"–ö–æ–ª-–≤–æ –ø–æ—Å—Ç–æ–≤\",  # num\n",
    "]]\n",
    "y = df[\"–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "##################################\n",
    "# –®–∞–≥ 3: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é + c–æ–±–∏—Ä–∞–µ–º Pipeline \n",
    "##################################\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ ColumnTransformer –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            'desc_tfidf',  # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π \n",
    "            Pipeline([\n",
    "                ('text_cleaner', TextCleaner()),\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english',  # –°—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "                                          ngram_range=(1, 3),  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç—Ä–∏–≥—Ä–∞–º–º\n",
    "                                          max_features=3500,  # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "                                          sublinear_tf=True)  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞ –¥–ª—è —á–∞—Å—Ç–æ—Ç—ã —Ç–µ—Ä–º–∏–Ω–æ–≤\n",
    "                ),\n",
    "            ]),\n",
    "            '–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã'\n",
    "            \n",
    "        ),\n",
    "        (\n",
    "            'desc_links_binarizer',\n",
    "            Pipeline([\n",
    "                ('binarizer', DomainBinarizer())\n",
    "                # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å StandardScaler() ‚Äî\n",
    "                # –Ω–æ –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö —Ñ–∏—á —ç—Ç–æ –æ–±—ã—á–Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ\n",
    "            ]),\n",
    "            '–°—Å—ã–ª–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è'\n",
    "        ),\n",
    "        (\n",
    "            'contact_links_binarizer',\n",
    "            Pipeline([\n",
    "                ('binarizer', DomainBinarizer())\n",
    "            ]),\n",
    "            '–°—Å—ã–ª–∫–∏ –∏–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤'\n",
    "        ),\n",
    "        (\n",
    "            'binary', \n",
    "            'passthrough',  # –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "            ['–ü–æ—á—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç']\n",
    "        ),\n",
    "        (\n",
    "            'num_scaler', \n",
    "            StandardScaler(),  # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "            ['–ö–æ–ª-–≤–æ –ø–æ—Å—Ç–æ–≤']\n",
    "        ),\n",
    "    ],\n",
    "    remainder='drop'  # –£–¥–∞–ª—è–µ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å\n",
    ")\n",
    "\n",
    "\n",
    "##################################\n",
    "# –®–∞–≥ 4: –°–æ–±–∏—Ä–∞–µ–º Pipeline\n",
    "##################################\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ —Ä–µ—Å—ç–º–ø–ª–∏–Ω–≥–∞\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),  # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —á–∏—Å–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ SMOTE.\n",
    "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000)),\n",
    "])\n",
    "\n",
    "# ##################################\n",
    "# # –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞\n",
    "# ##################################\n",
    "\n",
    "# –û–±—É—á–∞–µ–º\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# –°–º–æ—Ç—Ä–∏–º –æ—Ç—á—ë—Ç\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª–µ data/mod–µls/account_type.pkl\n",
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞ data/mod–µls/account_type.pkl\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã: [<AccountType.BEATMAKER: 'BEATMAKER'>]\n",
      "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤: [[0.06444823 0.85820526 0.02759148 0.03312428 0.01663076]]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "##################################\n",
    "# –®–∞–≥ 6: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –∏–º–µ—é—â–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö\n",
    "##################################\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "##################################\n",
    "# –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "##################################\n",
    "\n",
    "model_path = 'data/mod–µls/account_type.pkl'\n",
    "joblib.dump(pipeline, model_path)\n",
    "print(f\"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª–µ {model_path}\")\n",
    "\n",
    "\n",
    "##################################\n",
    "# –®–∞–≥ 8: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "##################################\n",
    "\n",
    "loaded_model = joblib.load(model_path)\n",
    "print(f\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞ {model_path}\")\n",
    "\n",
    "\n",
    "##################################\n",
    "# –®–∞–≥ 9: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "##################################\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    '–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã': [\n",
    "        '''Colt Blumenthal\n",
    "mixedbycolt\n",
    "üöÄ #1 Billboard Engineer, üíø Multi-Platinum\n",
    "üíªEngineered for 100+ Major Artists\n",
    "üèÖ SAE Institute Alumni Hall of Fame\n",
    "üîäPremium Mixing & Mastering Service\n",
    "linktr.ee/mixedbycolt'''\n",
    "    ],\n",
    "    '–°—Å—ã–ª–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è': [\n",
    "        [\n",
    "            'https://linktr.ee/mixedbycolt?fbclid=PAZXh0bgNhZW0CMTEAAaYAv9ZUzP17l1o8wVsSVjvTAzUJT9CppNIKLuP0FENyTVKEOAH3OmmBnCA_aem_FRFJBiIdaHkZ9aYHEaCLHQ',\n",
    "            'https://www.instagram.com/explore/tags/1/',\n",
    "            'https://www.threads.net/@mixedbycolt?xmt=AQGzUA43HPJ5PxWfBGKXf29C7EUpu6r6IVFcdtq1jbBJa8Y'\n",
    "        ]\n",
    "    ],\n",
    "    '–°—Å—ã–ª–∫–∏ –∏–∑ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤': [\n",
    "        ''\n",
    "        # 'https://soundcloud.com/playlist/ddw31e\\nhttps://youtube.com/watch?v=12345'\n",
    "    ],\n",
    "    '–ü–æ—á—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç': [0],\n",
    "    '–ö–æ–ª-–≤–æ –ø–æ—Å—Ç–æ–≤': [90]\n",
    "})\n",
    "\n",
    "preds = loaded_model.predict(new_data)\n",
    "preds_enum = [AccountType(s) for s in preds]  # [AccountType.ARTIST, AccountType.LABEL, ...]\n",
    "\n",
    "print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã:\", preds_enum)\n",
    "\n",
    "proba = loaded_model.predict_proba(new_data)\n",
    "print(\"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤:\", proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥—Å—á–µ—Ç –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∞–∫–∫–∞—É–Ω—Ç–∞\n",
    "print(df['–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ \"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞\" == \"ARTIST\"\n",
    "df_artist = df[df[\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞\"] == \"ARTIST\"]\n",
    "\n",
    "# –°—á–∏—Ç–∞–µ–º —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ö—ç—à—Ç–µ–≥–∏ —Å—Ä–µ–¥–∏ —ç—Ç–∏—Ö —Å—Ç—Ä–æ–∫\n",
    "hashtags_count = df_artist[\"–•—ç—à—Ç–µ–≥, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –Ω–∞–π–¥–µ–Ω –∞–∫–∫–∞—É–Ω—Ç\"].value_counts()\n",
    "\n",
    "# –°–º–æ—Ç—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Ç–æ–ø 10, –Ω–∞–ø—Ä–∏–º–µ—Ä)\n",
    "print(hashtags_count.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_mask = df.duplicated()\n",
    "print(\"–ß–∏—Å–ª–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:\", duplicates_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from helpers.excel import write_excel\n",
    "\n",
    "from database.orm import async_session, get_all_accounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∞–ø–∫–∞ —Å —Ñ–∞–π–ª–∞–º–∏ .ods\n",
    "folder_path = 'data/mod–µls/tables'\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ .ods –≤ –ø–∞–ø–∫–µ\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.ods')]\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    data = pd.read_excel(file_path, engine='odf')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'odf' –¥–ª—è .ods —Ñ–∞–π–ª–æ–≤\n",
    "    \n",
    "    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    data['–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞ (–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤—Å–µ–≥–¥–∞). –ó–Ω–∞—á–µ–Ω–∏—è: ARTIST, BEATMAKER, LABEL, MARKET, COMMUNITY, OTHER'] = data['–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞ (–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤—Å–µ–≥–¥–∞). –ó–Ω–∞—á–µ–Ω–∏—è: ARTIST, BEATMAKER, LABEL, MARKET, COMMUNITY, OTHER'].replace(np.nan, 'OTHER')\n",
    "\n",
    "    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "    combined_df = pd.concat([combined_df, data], ignore_index=True)\n",
    "\n",
    "async def update_account_types(async_session, data: pd.DataFrame):\n",
    "    async with async_session() as session:\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫–∫–∞—É–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "        accounts = await get_all_accounts(async_session)\n",
    "\n",
    "        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –ø–æ —Å—Å—ã–ª–∫–µ\n",
    "        account_dict = {account.link: account for account in accounts}\n",
    "\n",
    "        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–∏–ø—ã –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ DataFrame\n",
    "        for _, row in data.iterrows():\n",
    "            link = row.get('–°—Å—ã–ª–∫–∞ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç').strip()\n",
    "            account_type = row.get('–¢–∏–ø –∞–∫–∫–∞—É–Ω—Ç–∞ (–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤—Å–µ–≥–¥–∞). –ó–Ω–∞—á–µ–Ω–∏—è: ARTIST, BEATMAKER, LABEL, MARKET, COMMUNITY, OTHER').strip()\n",
    "            # print(f'link: {link}')\n",
    "            # print(f'account_type: {account_type}')\n",
    "\n",
    "            if link in account_dict and account_type:\n",
    "                account = account_dict[link]\n",
    "                account.account_type = account_type\n",
    "                # print(f'account: {account.link}')\n",
    "                # print(f'account_type: {account.account_type}')\n",
    "                session.add(account)\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "        await session.commit()\n",
    "        \n",
    "await update_account_types(async_session, combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = await get_all_accounts(async_session)\n",
    "write_excel(accounts, out_path='data/mod–µls/row_data/merged_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
